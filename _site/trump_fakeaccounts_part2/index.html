<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.7.1 by Michael Rose
  Copyright 2017 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE.txt
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin SEO -->









<title>Estimating Trump’s Fake Twitter Followers: Part 2 - Paul Reidy</title>




<meta name="description" content="In the previous post I collected some data on a sample of Donald Trump’s Twitter followers and also assembled a training dataset. In this post I will try to use some simple machine learning models to estimate how many fake followers Trump may have. I will start by training and testing various machine learning models on the Varol et al. (2017) dataset. I will then use the trained models to classify bots in the Trump followers dataset that I have collected (which has no labels).">




<meta name="author" content="Paul Reidy">

<meta property="og:locale" content="en">
<meta property="og:site_name" content="Paul Reidy">
<meta property="og:title" content="Estimating Trump’s Fake Twitter Followers: Part 2">


  <link rel="canonical" href="http://localhost:4000/trump_fakeaccounts_part2/">
  <meta property="og:url" content="http://localhost:4000/trump_fakeaccounts_part2/">



  <meta property="og:description" content="In the previous post I collected some data on a sample of Donald Trump’s Twitter followers and also assembled a training dataset. In this post I will try to use some simple machine learning models to estimate how many fake followers Trump may have. I will start by training and testing various machine learning models on the Varol et al. (2017) dataset. I will then use the trained models to classify bots in the Trump followers dataset that I have collected (which has no labels).">

















  

  





  <meta property="og:type" content="article">
  <meta property="article:published_time" content="2017-12-24T16:45:00+00:00">








  <script type="application/ld+json">
    {
      "@context" : "http://schema.org",
      "@type" : "Person",
      "name" : "Paul Reidy",
      "url" : "http://localhost:4000",
      "sameAs" : null
    }
  </script>







<!-- end SEO -->


<link href="http://localhost:4000/feed.xml" type="application/atom+xml" rel="alternate" title="Paul Reidy Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="http://localhost:4000/assets/css/main.css">

<!--[if lte IE 9]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->


    <!-- start custom head snippets -->

<!-- insert favicons. use http://realfavicongenerator.net/ -->

<!-- end custom head snippets -->
  </head>

  <body class="layout--post">

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    <div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <a class="site-title" href="http://localhost:4000/">Paul Reidy</a>
        <ul class="visible-links">
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/">About</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/posts/">Posts</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/software/">Software</a></li>
          
        </ul>
        <button type="button">
          <span class="visually-hidden">Toggle Menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>

    <!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"><!--<![endif]-->

<body class="post">
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-110480715-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-110480715-1');
</script>

<div id="main" role="main">
  <article class="post">
    <h2><strong>Estimating Trump's Fake Twitter Followers: Part 2</strong></h2>
    <p><font size="3"><i><time datetime="2017-12-24T16:45:00+00:00">December 24, 2017</time> </i></font></p>
    <hr/>
           
    <p>In the previous post I collected some data on a sample of Donald Trump’s Twitter followers and also assembled a training dataset. In this post I will try to use some simple machine learning models to estimate how many fake followers Trump may have. I will start by training and testing various machine learning models on the Varol et al. (2017) <a href="https://botometer.iuni.iu.edu/bot-repository/datasets.html">dataset</a>. I will then use the trained models to classify bots in the Trump followers dataset that I have collected (which has no labels).</p>

<p>Before fitting any models it’s important to look at the features that we will use to train the models and make sure that there are no obvious errors. We will also need to do some preprocessing to make sure that the features will work with the models:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">datetime</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">rcParams</span>
<span class="kn">from</span> <span class="nn">matplotlib.ticker</span> <span class="kn">import</span> <span class="n">FuncFormatter</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.utils</span> <span class="kn">import</span> <span class="n">shuffle</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">learning_curve</span><span class="p">,</span> <span class="n">cross_val_score</span><span class="p">,</span> <span class="n">StratifiedKFold</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">roc_curve</span><span class="p">,</span> <span class="n">roc_auc_score</span><span class="p">,</span> <span class="n">auc</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s">'fivethirtyeight'</span><span class="p">)</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="n">rcParams</span><span class="p">[</span><span class="s">'figure.figsize'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

<span class="c"># Load data</span>
<span class="n">training_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'Data/varol2017_data/varol2017_training_data.csv'</span><span class="p">,</span> <span class="n">parse_dates</span><span class="o">=</span><span class="p">[</span><span class="s">'created_at'</span><span class="p">])</span>

<span class="c"># Convert boolean columns to int</span>
<span class="n">bool_cols</span> <span class="o">=</span> <span class="n">training_df</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="p">[</span><span class="nb">bool</span><span class="p">])</span><span class="o">.</span><span class="n">columns</span>
<span class="n">training_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">bool_cols</span><span class="p">]</span> <span class="o">=</span> <span class="n">training_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">bool_cols</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

<span class="c"># Cleaning up some features</span>
<span class="n">training_df</span><span class="p">[</span><span class="s">'followers_friends_ratio'</span><span class="p">]</span> <span class="o">=</span> <span class="p">((</span><span class="n">training_df</span><span class="p">[</span><span class="s">'followers_count'</span><span class="p">]</span> <span class="o">/</span> <span class="n">training_df</span><span class="p">[</span><span class="s">'friends_count'</span><span class="p">])</span>
                                          <span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">))</span> <span class="c"># remove any infinity values</span>
<span class="n">training_df</span><span class="p">[</span><span class="s">'description_len'</span><span class="p">]</span> <span class="o">=</span> <span class="n">training_df</span><span class="p">[</span><span class="s">'description'</span><span class="p">]</span><span class="o">.</span><span class="nb">str</span><span class="o">.</span><span class="nb">len</span><span class="p">()</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> 

<span class="c"># List of features</span>
<span class="n">training_df</span><span class="o">.</span><span class="n">columns</span>
</code></pre></div></div>

<p><img src="/assets/trump_fakeaccounts_part2_files/figure1.png" /></p>

<p>I will exclude features that we would expect to have little predictive value or that would be difficult to interpret. For example, <code class="highlighter-rouge">account_id</code> should not be able to predict whether an account is a bot and, even if it did, it’s not clear how we would interpret it (i.e., what does a one unit change in <code class="highlighter-rouge">account_id</code> mean?). I therefore exclude <code class="highlighter-rouge">account_id</code>, <code class="highlighter-rouge">name</code>, <code class="highlighter-rouge">screen_name</code> and <code class="highlighter-rouge">description</code> as features. If we wanted to use these features in the models we would have to transform them in some way so that they would make sense in the context of a model. For example, we already have a <code class="highlighter-rouge">description_len</code> feature which is the length in characters of the description provided on the Twitter account. This makes sense because it is a continuous value so we can use it in most machine learning models. I also drop the <code class="highlighter-rouge">lang</code> column from the dataset because all the accounts in the dataset are in English.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">training_df</span> <span class="o">=</span> <span class="n">training_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s">'account_id'</span><span class="p">,</span> <span class="s">'name'</span><span class="p">,</span> <span class="s">'screen_name'</span><span class="p">,</span> <span class="s">'description'</span><span class="p">,</span> <span class="s">'lang'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<p>There are some other features that we should transform before fitting any models. For example, a feature with the account creation date (e.g., 2015-03-19 22:14:20) may not make sense. But we can use this feature to calculate the account age in numbers of days which should work better.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">training_df</span><span class="p">[</span><span class="s">'account_age_days'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">datetime</span><span class="o">.</span><span class="n">datetime</span><span class="p">(</span><span class="mi">2017</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">18</span><span class="p">)</span> <span class="o">-</span> <span class="n">training_df</span><span class="p">[</span><span class="s">'created_at'</span><span class="p">])</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">days</span>
<span class="n">training_df</span> <span class="o">=</span> <span class="n">training_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s">'created_at'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">training_df</span><span class="p">[</span><span class="s">'account_age_days'</span><span class="p">]</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>
<p><img src="/assets/trump_fakeaccounts_part2_files/figure2.png" /></p>

<p>Next we can take a look at any categorical variables and ensure that they are in the correct format. The first step is to check that all categorical variables have been converted from strings to integer values.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">training_df</span><span class="p">[[</span><span class="s">'bot'</span><span class="p">,</span> <span class="s">'default_profile'</span><span class="p">,</span> <span class="s">'default_profile_image'</span><span class="p">,</span> <span class="s">'geo_enabled'</span><span class="p">,</span> <span class="s">'location'</span><span class="p">,</span> <span class="s">'protected'</span><span class="p">,</span> 
             <span class="s">'time_zone'</span><span class="p">,</span> <span class="s">'verified'</span><span class="p">]]</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>
<p><img src="/assets/trump_fakeaccounts_part2_files/figure3.png" /></p>

<p><code class="highlighter-rouge">bot</code>, <code class="highlighter-rouge">default_profile</code>, <code class="highlighter-rouge">default_profile_image</code>, <code class="highlighter-rouge">geo_enabled</code>, <code class="highlighter-rouge">protected</code>, and <code class="highlighter-rouge">verified</code> are all binary variables and have already been encoded as 0 (no) or 1 (yes).</p>

<p><code class="highlighter-rouge">location</code> and <code class="highlighter-rouge">time_zone</code> have not been transformed to integer values. These variables have more than two possible categories. We could transform them in a similar way to the binary variables. For example, if there were five categories in <code class="highlighter-rouge">location</code> we could replace each value in the column with a value in [0, 1, 2, 3, 4] depending on the category. But the problem with this is that it implies that the “distance” between each of the categories is the same and that the order of the categories has some meaning. These are generally not good assumptions so instead we should use <a href="http://scikit-learn.org/stable/modules/preprocessing.html#encoding-categorical-features">One-Hot Encoding</a> or <a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html">pd.get_dummies</a>. In this method we create a new column for each category in an existing column and create a binary value for this category. For example, if the values of location are ‘USA’, ‘England’, and ‘France’ then we would have three new columns and if a new observation has a value of ‘USA’ we would have [1, 0, 0].</p>

<p>However, the <code class="highlighter-rouge">location</code> feature has a very large number of values and many of them overlap because the account owner can enter this description manually rather than choosing from a pre-defined set of locations. For example, many accounts have “United States” as the location while others have “USA” or the name of a US city of US state. If we wanted to use the column as a feature in the models we would have to try to combine a lot of the unique values. In addition, the account owner can enter any value that they wish in this field so it may not be reliable even if we manage to clean it up. For these reasons I will drop this column from the analysis.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">training_df</span><span class="p">[</span><span class="s">'location'</span><span class="p">]</span><span class="o">.</span><span class="n">nunique</span><span class="p">()</span>
</code></pre></div></div>

<p>1248</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">training_df</span><span class="p">[</span><span class="s">'location'</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()[:</span><span class="mi">10</span><span class="p">]</span>
</code></pre></div></div>
<p><img src="/assets/trump_fakeaccounts_part2_files/figure4.png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">training_df</span> <span class="o">=</span> <span class="n">training_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s">'location'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<p>The number of unique values for the <code class="highlighter-rouge">time_zone</code> column is much smaller than location but it’s not clear if time-zone would be a good predictor of bot status so I will exclude it for now.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">training_df</span><span class="p">[</span><span class="s">'time_zone'</span><span class="p">]</span><span class="o">.</span><span class="n">nunique</span><span class="p">()</span>
<span class="n">training_df</span> <span class="o">=</span> <span class="n">training_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s">'time_zone'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<p>After this pre-processing we are left with the following features:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">training_df</span><span class="o">.</span><span class="n">columns</span>
</code></pre></div></div>
<p><img src="/assets/trump_fakeaccounts_part2_files/figure5.png" /></p>

<h2 id="useful-diagnostic-functions">Useful Diagnostic Functions</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">draw_roc_curve</span><span class="p">(</span><span class="n">y_val</span><span class="p">,</span> <span class="n">model_probs_target</span><span class="p">,</span> <span class="n">ax</span><span class="p">,</span> <span class="n">fold_num</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="s">"""Draw the ROC curve given the true y values (y_val) and 
    the probability estimates of the target class (model_probs_val)"""</span>
    
    <span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_val</span><span class="p">,</span> <span class="n">model_probs_target</span><span class="p">)</span>  
    <span class="n">roc_auc</span> <span class="o">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">fold_num</span><span class="p">:</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'ROC fold {} (AUC = {:.2f})'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">fold_num</span><span class="p">,</span> <span class="n">roc_auc</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="p">(</span><span class="s">'AUC = {:.2f}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">roc_auc</span><span class="p">)))</span>
    
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">'ROC Curve'</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">'True Positive Rate'</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">'False Positive Rate'</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="s">'medium'</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">draw_learning_curve</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">X_data</span><span class="p">,</span> <span class="n">y_data</span><span class="p">,</span> <span class="n">ax</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
    <span class="s">"""Draw the learning curve given the instantiated estimator, the full matrix of 
    features (X_data) and the response variable (y_data) for the training data"""</span>
    <span class="n">train_sizes</span><span class="p">,</span> <span class="n">train_scores</span><span class="p">,</span> <span class="n">valid_scores</span> <span class="o">=</span> <span class="n">learning_curve</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X_data</span><span class="p">,</span> 
                                                             <span class="n">y</span><span class="o">=</span><span class="n">y_data</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
                                                             <span class="n">random_state</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> 
                                                             <span class="n">train_sizes</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1250</span><span class="p">,</span> <span class="mi">15</span><span class="p">)))</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">train_sizes</span><span class="p">,</span> <span class="n">train_scores</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s">'Training Score'</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">train_sizes</span><span class="p">,</span> <span class="n">valid_scores</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s">'Cross-Validation Score'</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">"Learning Curve"</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">'Score'</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">'Training Examples'</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="s">'medium'</span><span class="p">)</span>
    
<span class="k">def</span> <span class="nf">classification_stats</span><span class="p">(</span><span class="n">y_val</span><span class="p">,</span> <span class="n">model_pred</span><span class="p">,</span> <span class="n">model_probs_target</span><span class="p">):</span>
    <span class="s">"""Calculate and present some useful classification statistics.
    It takes the true y values (y_val), the predicted y values (model pred),  
    the predicted probability of y=1 for the model (model_probs_target). 
    It returns a list of the classification accuracy, the true negative rate, 
    the true positive rate, the AUC, and the confusion matrix."""</span>
    
    <span class="n">classification_accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_val</span><span class="p">,</span> <span class="n">model_pred</span><span class="p">)</span>
    <span class="n">tn</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="n">tp</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_val</span><span class="p">,</span> <span class="n">model_pred</span><span class="p">)</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
    <span class="n">true_neg_rate</span> <span class="o">=</span> <span class="n">tn</span> <span class="o">/</span> <span class="p">(</span><span class="n">tn</span> <span class="o">+</span> <span class="n">fp</span><span class="p">)</span>
    <span class="n">true_pos_rate</span> <span class="o">=</span> <span class="n">tp</span> <span class="o">/</span> <span class="p">(</span><span class="n">tp</span> <span class="o">+</span> <span class="n">fn</span><span class="p">)</span>
    <span class="n">auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_val</span><span class="p">,</span> <span class="n">model_probs_target</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">con_matrix</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_val</span><span class="p">,</span> <span class="n">model_pred</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="p">[</span><span class="n">classification_accuracy</span><span class="p">,</span> <span class="n">true_neg_rate</span><span class="p">,</span> <span class="n">true_pos_rate</span><span class="p">,</span> <span class="n">auc</span><span class="p">,</span> <span class="n">con_matrix</span><span class="p">]</span>
</code></pre></div></div>

<h2 id="train-validation-test-split">Train-Validation-Test Split</h2>
<p>I split the Varol et al. (2017) data into two parts. The training and validation set is 70% of the data. I use k-fold cross-validation to choose the parameters for a <em>particular</em> model (e.g., choosing the number of features in a logistic regression model). After the parameters of the model have been chosen then I estimate the out-of-sample performance using the test set which is the remaining 30% of the data. This test set should give a fair reflection of the performance of the model on unseen data and I use this to choose <em>between</em> models (e.g., random forests vs. logistic regression).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_train_full</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train_full</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">training_df</span><span class="p">[</span><span class="n">training_df</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">difference</span><span class="p">([</span><span class="s">'bot'</span><span class="p">])],</span> 
                                                              <span class="n">training_df</span><span class="p">[</span><span class="s">'bot'</span><span class="p">],</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
                                                              <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">X_train_full</span> <span class="o">=</span> <span class="n">X_train_full</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">how</span><span class="o">=</span><span class="s">'any'</span><span class="p">)</span>
<span class="n">y_train_full</span> <span class="o">=</span> <span class="n">y_train_full</span><span class="p">[</span><span class="n">X_train_full</span><span class="o">.</span><span class="n">index</span><span class="p">]</span>
</code></pre></div></div>

<h2 id="logistic-regression">Logistic Regression</h2>
<p>To start with, I will fit a simple Logistic Regression model with all of the features and then perform some model diagnostics to try to see if we can improve performance.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Initialize cross-validation and logistic regression</span>
<span class="n">cv</span> <span class="o">=</span> <span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">logistic</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">{}</span>

<span class="c"># Perform cross-validation</span>
<span class="n">f</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">fold_num</span> <span class="o">=</span> <span class="mi">1</span>
<span class="k">for</span> <span class="n">temp_train_index</span><span class="p">,</span> <span class="n">temp_val_index</span> <span class="ow">in</span> <span class="n">cv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X_train_full</span><span class="p">,</span> <span class="n">y_train_full</span><span class="p">):</span>
    <span class="n">logistic</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_full</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">temp_train_index</span><span class="p">],</span> <span class="n">y_train_full</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">temp_train_index</span><span class="p">])</span>
    <span class="n">logistic_pred_val</span> <span class="o">=</span> <span class="n">logistic</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train_full</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">temp_val_index</span><span class="p">])</span>
    <span class="n">logistic_probs_val</span> <span class="o">=</span> <span class="n">logistic</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_train_full</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">temp_val_index</span><span class="p">])</span>
    <span class="n">data</span><span class="p">[</span><span class="n">fold_num</span><span class="p">]</span> <span class="o">=</span> <span class="n">classification_stats</span><span class="p">(</span><span class="n">y_train_full</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">temp_val_index</span><span class="p">],</span> <span class="n">logistic_pred_val</span><span class="p">,</span> <span class="n">logistic_probs_val</span><span class="p">)</span>
    <span class="n">draw_roc_curve</span><span class="p">(</span><span class="n">y_train_full</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">temp_val_index</span><span class="p">],</span> <span class="n">logistic_probs_val</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">ax1</span><span class="p">,</span> <span class="n">fold_num</span><span class="p">)</span>
    <span class="n">fold_num</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="n">draw_learning_curve</span><span class="p">(</span><span class="n">logistic</span><span class="p">,</span> <span class="n">X_train_full</span><span class="p">,</span> <span class="n">y_train_full</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Average Cross Validation Score {:.4f}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">logistic</span><span class="p">,</span> 
                                                     <span class="n">X_train_full</span><span class="p">,</span> <span class="n">y_train_full</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()))</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">values</span><span class="p">()),</span> 
             <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">'classification_accuracy'</span><span class="p">,</span> <span class="s">'true_neg_rate'</span><span class="p">,</span> 
                      <span class="s">'true_pos_rate'</span><span class="p">,</span> <span class="s">'AUC'</span><span class="p">,</span> <span class="s">'confusion_matrix'</span><span class="p">],</span>
            <span class="n">index</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
</code></pre></div></div>

<p>Average Cross Validation Score 0.7246</p>

<p><img src="/assets/trump_fakeaccounts_part2_files/figure6.png" /></p>

<p><img src="/assets/trump_fakeaccounts_part2_files/trump_fakeaccounts_part2_21_2.png" alt="png" /></p>

<h3 id="model-diagnostics">Model Diagnostics</h3>

<p>The learning curve shows that there is only a very small gap between the training score and the cross-validation score and so there doesn’t appear to be a high variance problem. This suggests that gathering more data would not be helpful. The training and cross-validation scores also appear to be quite high (i.e., the errors are low) so there does not appear to be a bias problem. Therefore, it’s not clear what we can do to improve this model so let’s move on to the Random Forest model.</p>

<h2 id="random-forest">Random Forest</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cv</span> <span class="o">=</span> <span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">{}</span>

<span class="c"># Perform cross-validation</span>
<span class="n">f</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">fold_num</span> <span class="o">=</span> <span class="mi">1</span>
<span class="k">for</span> <span class="n">temp_train_index</span><span class="p">,</span> <span class="n">temp_val_index</span> <span class="ow">in</span> <span class="n">cv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X_train_full</span><span class="p">,</span> <span class="n">y_train_full</span><span class="p">):</span>
    <span class="n">rf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_full</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">temp_train_index</span><span class="p">],</span> <span class="n">y_train_full</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">temp_train_index</span><span class="p">])</span>
    <span class="n">rf_pred_val</span> <span class="o">=</span> <span class="n">rf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train_full</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">temp_val_index</span><span class="p">])</span>
    <span class="n">rf_probs_val</span> <span class="o">=</span> <span class="n">rf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_train_full</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">temp_val_index</span><span class="p">])</span>
    <span class="n">data</span><span class="p">[</span><span class="n">fold_num</span><span class="p">]</span> <span class="o">=</span> <span class="n">classification_stats</span><span class="p">(</span><span class="n">y_train_full</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">temp_val_index</span><span class="p">],</span> <span class="n">rf_pred_val</span><span class="p">,</span> <span class="n">rf_probs_val</span><span class="p">)</span>
    <span class="n">draw_roc_curve</span><span class="p">(</span><span class="n">y_train_full</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">temp_val_index</span><span class="p">],</span> <span class="n">rf_probs_val</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">ax1</span><span class="p">,</span> <span class="n">fold_num</span><span class="p">)</span>
    <span class="n">fold_num</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="n">draw_learning_curve</span><span class="p">(</span><span class="n">rf</span><span class="p">,</span> <span class="n">X_train_full</span><span class="p">,</span> <span class="n">y_train_full</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Average Cross Validation Score {:.4f}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">rf</span><span class="p">,</span> 
                                                     <span class="n">X_train_full</span><span class="p">,</span> <span class="n">y_train_full</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()))</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">values</span><span class="p">()),</span> 
             <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">'classification_accuracy'</span><span class="p">,</span> <span class="s">'true_neg_rate'</span><span class="p">,</span> 
                      <span class="s">'true_pos_rate'</span><span class="p">,</span> <span class="s">'AUC'</span><span class="p">,</span> <span class="s">'confusion_matrix'</span><span class="p">],</span>
             <span class="n">index</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
</code></pre></div></div>

<p>Average Cross Validation Score 0.7517</p>

<p><img src="/assets/trump_fakeaccounts_part2_files/figure7.png" /></p>

<p><img src="/assets/trump_fakeaccounts_part2_files/trump_fakeaccounts_part2_24_2.png" alt="png" /></p>

<h3 id="model-diagnostics-1">Model Diagnostics</h3>
<p>The random forests classifier achieves an almost perfect score on the training dataset but the score is much lower on the cross-validation set. This suggests that the model is overfitting the training data and that we have a high variance problem rather than a high bias problem. It may be possible to solve this problem by gathering more data or by reducing the complexity of the model. I can’t gather more training data in this case so I will try to reduce the model complexity by reducing the number of features. In a Random Forests model we can get information on the importance of each of the features. I will use the top 5 most important features in the new Random Forests model.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Which features are most important in the random forests model above?</span>
<span class="n">feature_ranking</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">X_train_full</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">rf</span><span class="o">.</span><span class="n">feature_importances_</span><span class="p">)),</span> 
                         <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">tup</span><span class="p">:</span> <span class="n">tup</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="k">for</span> <span class="n">feature</span><span class="p">,</span> <span class="n">importance</span> <span class="ow">in</span> <span class="n">feature_ranking</span><span class="p">[:</span><span class="mi">5</span><span class="p">]:</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"{}: {:.4f}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">feature</span><span class="p">,</span> <span class="n">importance</span><span class="p">))</span>

<span class="c"># Keep top 5 features</span>
<span class="n">top5_features</span> <span class="o">=</span> <span class="p">[</span><span class="n">tup</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">tup</span> <span class="ow">in</span> <span class="n">feature_ranking</span><span class="p">[:</span><span class="mi">5</span><span class="p">]]</span>

<span class="n">X_train_rf_top5</span> <span class="o">=</span> <span class="n">X_train_full</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">top5_features</span><span class="p">]</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">how</span><span class="o">=</span><span class="s">'any'</span><span class="p">)</span>
<span class="n">y_train_rf_top5</span> <span class="o">=</span> <span class="n">y_train_full</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">X_train_rf_top5</span><span class="o">.</span><span class="n">index</span><span class="p">]</span>
</code></pre></div></div>
<p><img src="/assets/trump_fakeaccounts_part2_files/figure8.png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span> <span class="o">=</span> <span class="p">{}</span>

<span class="c"># Perform cross-validation</span>
<span class="n">f</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">fold_num</span> <span class="o">=</span> <span class="mi">1</span>
<span class="k">for</span> <span class="n">temp_train_index</span><span class="p">,</span> <span class="n">temp_val_index</span> <span class="ow">in</span> <span class="n">cv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X_train_rf_top5</span><span class="p">,</span> <span class="n">y_train_rf_top5</span><span class="p">):</span>
    <span class="n">rf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_rf_top5</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">temp_train_index</span><span class="p">],</span> <span class="n">y_train_rf_top5</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">temp_train_index</span><span class="p">])</span>
    <span class="n">rf_pred_val</span> <span class="o">=</span> <span class="n">rf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train_rf_top5</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">temp_val_index</span><span class="p">])</span>
    <span class="n">rf_probs_val</span> <span class="o">=</span> <span class="n">rf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_train_rf_top5</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">temp_val_index</span><span class="p">])</span>
    <span class="n">data</span><span class="p">[</span><span class="n">fold_num</span><span class="p">]</span> <span class="o">=</span> <span class="n">classification_stats</span><span class="p">(</span><span class="n">y_train_rf_top5</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">temp_val_index</span><span class="p">],</span> 
                                          <span class="n">rf_pred_val</span><span class="p">,</span> <span class="n">rf_probs_val</span><span class="p">)</span>
    <span class="n">draw_roc_curve</span><span class="p">(</span><span class="n">y_train_rf_top5</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">temp_val_index</span><span class="p">],</span> <span class="n">rf_probs_val</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">ax1</span><span class="p">,</span> <span class="n">fold_num</span><span class="p">)</span>
    <span class="n">fold_num</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="n">draw_learning_curve</span><span class="p">(</span><span class="n">rf</span><span class="p">,</span> <span class="n">X_train_rf_top5</span><span class="p">,</span> <span class="n">y_train_rf_top5</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Average Cross Validation Score {:.4f}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">rf</span><span class="p">,</span> 
                                                     <span class="n">X_train_rf_top5</span><span class="p">,</span> <span class="n">y_train_rf_top5</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()))</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">values</span><span class="p">()),</span> 
             <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">'classification_accuracy'</span><span class="p">,</span> <span class="s">'true_neg_rate'</span><span class="p">,</span> 
                      <span class="s">'true_pos_rate'</span><span class="p">,</span> <span class="s">'AUC'</span><span class="p">,</span> <span class="s">'confusion_matrix'</span><span class="p">],</span>
            <span class="n">index</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
</code></pre></div></div>

<p>Average Cross Validation Score 0.7443</p>

<p><img src="/assets/trump_fakeaccounts_part2_files/figure9.png" /></p>

<p><img src="/assets/trump_fakeaccounts_part2_files/trump_fakeaccounts_part2_27_2.png" alt="png" /></p>

<p>There does not appear to be any improvement by reducing the complexity of the model (and I get similar results using only the top 3 or top 10 features). Ideally, we could get more training data to try to solve this problem but this is not possible in this case.</p>

<h1 id="choosing-the-model">Choosing the Model</h1>
<p>So far we have trained our two models and tried to diagnose and improve their performance. Now let’s see how each of the models perform on the test dataset which was not used in training or diagnosing the models. We achieved the best performance for both the Logistic Regression and the Random Forests when using all of the features so we will first train the models using the full training dataset (i.e., without any cross-validation this time):</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">logistic</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">logistic</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_full</span><span class="p">,</span> <span class="n">y_train_full</span><span class="p">)</span>

<span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">rf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_full</span><span class="p">,</span> <span class="n">y_train_full</span><span class="p">);</span>
</code></pre></div></div>

<p>Now let’s test the models using the test dataset and compare performance:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">how</span><span class="o">=</span><span class="s">'any'</span><span class="p">)</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">y_test</span><span class="p">[</span><span class="n">X_test</span><span class="o">.</span><span class="n">index</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">logistic_pred_test</span> <span class="o">=</span> <span class="n">logistic</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">logistic_probs_test</span> <span class="o">=</span> <span class="n">logistic</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">logistic_pred_test</span><span class="p">)</span> <span class="c"># Same as (y_test == logistic_pred_test).mean()</span>
</code></pre></div></div>

<p>0.75428571428571434</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">rf_pred_test</span> <span class="o">=</span> <span class="n">rf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">rf_probs_test</span> <span class="o">=</span> <span class="n">rf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">rf_pred_test</span><span class="p">)</span> <span class="c"># Same as (y_test == rf_pred_test).mean()</span>
</code></pre></div></div>

<p>0.74285714285714288</p>

<p>We achieve remarkably good performance using both the logistic regression and random forests model on the test data. The performance of both models is very close to the cross-validated scores on the training dataset. The logistic regression has a slightly higher accuracy score on the test set so we will use this model to estimate the number of fake followers.</p>

<h1 id="trump-followers-data">Trump Followers Data</h1>
<p>Now we can apply the model that we have trained to the dataset that we collected in the previous post. First, we need to apply the same preprocessing and feature engineering methods that we used for the training dataset:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">trump_followers_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'Data/trump_followers/TrumpFollowers_cleaned.csv'</span><span class="p">,</span> <span class="n">parse_dates</span><span class="o">=</span><span class="p">[</span><span class="s">'created_at'</span><span class="p">])</span>

<span class="c"># Perform same preprocessing as above</span>
<span class="n">trump_followers_df</span><span class="p">[</span><span class="s">'account_age_days'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">datetime</span><span class="o">.</span><span class="n">datetime</span><span class="p">(</span><span class="mi">2017</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">18</span><span class="p">)</span> <span class="o">-</span> <span class="n">trump_followers_df</span><span class="p">[</span><span class="s">'created_at'</span><span class="p">])</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">days</span>
<span class="n">trump_followers_df</span> <span class="o">=</span> <span class="n">trump_followers_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s">'created_at'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">trump_followers_df</span><span class="p">[</span><span class="s">'followers_friends_ratio'</span><span class="p">]</span> <span class="o">=</span> <span class="p">((</span><span class="n">trump_followers_df</span><span class="p">[</span><span class="s">'followers_count'</span><span class="p">]</span> <span class="o">/</span> <span class="n">trump_followers_df</span><span class="p">[</span><span class="s">'friends_count'</span><span class="p">])</span>
                                          <span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">))</span> <span class="c"># remove any infinity values</span>
<span class="n">trump_followers_df</span><span class="p">[</span><span class="s">'description_len'</span><span class="p">]</span> <span class="o">=</span> <span class="n">trump_followers_df</span><span class="p">[</span><span class="s">'description'</span><span class="p">]</span><span class="o">.</span><span class="nb">str</span><span class="o">.</span><span class="nb">len</span><span class="p">()</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> 
<span class="n">trump_followers_df</span> <span class="o">=</span> <span class="n">trump_followers_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s">'id'</span><span class="p">,</span> <span class="s">'name'</span><span class="p">,</span> <span class="s">'screen_name'</span><span class="p">,</span> <span class="s">'description'</span><span class="p">,</span> <span class="s">'lang'</span><span class="p">,</span>
                                     <span class="s">'location'</span><span class="p">,</span> <span class="s">'time_zone'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">trump_followers_df</span> <span class="o">=</span> <span class="n">trump_followers_df</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">how</span><span class="o">=</span><span class="s">'any'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">rf_pred_trump</span> <span class="o">=</span> <span class="n">rf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">trump_followers_df</span><span class="p">)</span>
<span class="n">logistic_pred_trump</span> <span class="o">=</span> <span class="n">logistic</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">trump_followers_df</span><span class="p">)</span>

<span class="n">logistic_pred_trump</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</code></pre></div></div>

<p>0.37424151781898984</p>

<p>So using the logistic regression model we estimate that between 37.42% of Trump’s followers might not be real accounts. This estimates are broadly in line with previous work. However, we should note several limitations of this analysis.</p>

<p>First, the nature of fake accounts on Twitter is constantly evolving and the techniques used to escape detection are increasingly sophisticated. This means that using the dataset compiled by Varol et al. (2017) may cause us to miss out on some of the newer bots. Additionally, the behaviour of bots captured in the Varol et al. data may differ from the bots that follow Trump.</p>

<p>Second, we used to Twitter API to get a sample of the 40 million accounts that follow Trump but, as noted in the previous blog post, the sample was not random. Instead, the <code class="highlighter-rouge">Cursor</code> object returns followers in the order in which they were added. This could bias our estimate of the number of Trump fake followers. For example, if Trump’s more recent followers are more likely to be bots then we may overestimate the number of fake accounts that follow Trump.</p>

<p>Third, the sample size was also very small (approx. 11,000). It seems likely that the estimate of Trump’s fake following could change significantly if we gathered another sample. To get a more stable estimate of the number of fake accounts following Trump we may need a much larger sample.</p>


 
  </article>
</div>


<!-- <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="http://localhost:4000/assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>
<script src="http://localhost:4000/assets/js/scripts.min.js"></script>

	         -->

</body>
</html>

    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    
    
    
    
      <li><a href="https://github.com/reidy-p"><i class="fa fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
    
    
    
    <!-- <li><a href="http://localhost:4000/feed.xml"><i class="fa fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li> -->
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2017 Paul Reidy. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="http://localhost:4000/assets/js/main.min.js"></script>








  </body>
</html>